{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["buttonStyle","margin","padding","border","borderRadius","backgroundColor","color","fontSize","cursor","transition","App","videoRef","useRef","canvasRef","audioContextRef","analyserRef","referenceDescriptorsRef","isMonitoringRef","isReferenceCaptured","setIsReferenceCaptured","useState","proxyDetected","setProxyDetected","audioProxyDetected","setAudioProxyDetected","faceExpressions","setFaceExpressions","statusMessage","setStatusMessage","isCameraOn","setIsCameraOn","useEffect","async","modelPath","Promise","all","faceapi","tinyFaceDetector","loadFromUri","faceLandmark68Net","faceRecognitionNet","faceExpressionNet","error","console","loadModels","drawFaceTracking","useCallback","detections","current","canvas","ctx","getContext","width","videoWidth","height","videoHeight","clearRect","forEach","det","x","y","detection","box","some","refDesc","descriptor","strokeStyle","lineWidth","strokeRect","font","fillStyle","fillText","getMostLikelyExpression","expressions","Object","entries","reduce","acc","_ref","expr","value","expression","startAudioDetection","detectAudio","bufferLength","frequencyBinCount","dataArray","Uint8Array","getByteFrequencyData","isNoiseDetected","Math","sqrt","sum","val","isMultipleVoices","filter","length","requestAnimationFrame","startFaceDetection","detectFaces","withFaceLandmarks","withFaceDescriptors","withFaceExpressions","newExpressions","isProxyFound","index","clearCanvas","React","createElement","style","textAlign","marginTop","fontFamily","position","display","ref","autoPlay","playsInline","top","left","Fragment","onClick","map","startMonitoring","stopMonitoring","stopCamera","_videoRef$current","stream","srcObject","getTracks","track","stop","close","navigator","mediaDevices","getUserMedia","video","audio","window","AudioContext","webkitAudioContext","audioStream","createMediaStreamSource","createAnalyser","connect","_ref2","face","key","fontWeight","reportWebVitals","onPerfEntry","Function","__webpack_require__","e","then","bind","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","createRoot","document","getElementById","render","StrictMode"],"mappings":"sQAGA,MAgUMA,EAAc,CAClBC,OAAQ,MACRC,QAAS,YACTC,OAAQ,OACRC,aAAc,MACdC,gBAAiB,UACjBC,MAAO,OACPC,SAAU,OACVC,OAAQ,UACRC,WAAY,yBAECC,MA3UHA,KACV,MAAMC,EAAWC,iBAAO,MAClBC,EAAYD,iBAAO,MACnBE,EAAkBF,iBAAO,MACzBG,EAAcH,iBAAO,MAErBI,EAA0BJ,iBAAO,IACjCK,EAAkBL,kBAAO,IAExBM,EAAqBC,GAA0BC,oBAAS,IACxDC,EAAeC,GAAoBF,oBAAS,IAC5CG,EAAoBC,GAAyBJ,oBAAS,IACtDK,EAAiBC,GAAsBN,mBAAS,KAChDO,EAAeC,GAAoBR,mBAAS,sBAC5CS,EAAYC,GAAiBV,oBAAS,GAO7CW,oBAAU,KACWC,WACjB,IACE,MAAMC,EAAY,gBAEZC,QAAQC,IAAI,CAChBC,IAAaC,iBAAiBC,YAAYL,GAC1CG,IAAaG,kBAAkBD,YAAYL,GAC3CG,IAAaI,mBAAmBF,YAAYL,GAC5CG,IAAaK,kBAAkBH,YAAYL,KAG7CL,EAAiB,+CACjB,MAAOc,GACPC,QAAQD,MAAM,wBAAyBA,GACvCd,EAAiB,0DAIrBgB,IACC,IAGH,MA0DMC,EAAmBC,sBAAaC,IACpC,IAAKlC,EAAUmC,UAAYrC,EAASqC,QAAS,OAE7C,MAAMC,EAASpC,EAAUmC,QACnBE,EAAMD,EAAOE,WAAW,MAC9BF,EAAOG,MAAQzC,EAASqC,QAAQK,WAChCJ,EAAOK,OAAS3C,EAASqC,QAAQO,YACjCL,EAAIM,UAAU,EAAG,EAAGP,EAAOG,MAAOH,EAAOK,QAEzCP,EAAWU,QAASC,IAClB,MAAMC,EAAEA,EAACC,EAAEA,EAACR,MAAEA,EAAKE,OAAEA,GAAWI,EAAIG,UAAUC,IACxCxD,EACJU,EAAwBgC,QAAQe,KAC7BC,GAAY5B,IAA0BsB,EAAIO,WAAYD,GAnG7C,IAqGR,QACA,MAENd,EAAIgB,YAAc5D,EAClB4C,EAAIiB,UAAY,EAChBjB,EAAIkB,WAAWT,EAAGC,EAAGR,EAAOE,GAE5BJ,EAAImB,KAAO,aACXnB,EAAIoB,UAAYhE,EAChB4C,EAAIqB,SAASC,EAAwBd,EAAIe,aAAcd,EAAGC,EAAI,MAE/D,IAGGY,EAA2BC,GACxBC,OAAOC,QAAQF,GAAaG,OAAO,CAACC,EAAGC,KAAA,IAAGC,EAAMC,GAAMF,EAAA,OAC3DE,EAAQH,EAAIG,MAAQ,CAAEC,WAAYF,EAAMC,SAAUH,GAClD,CAAEI,WAAY,GAAID,MAAO,IAAKC,WAI5BC,EAAsBpC,sBAAY,KACtC,MAAMqC,EAAcA,KAClB,IAAKlE,EAAgB+B,UAAYjC,EAAYiC,QAAS,OAEtD,MAAMoC,EAAerE,EAAYiC,QAAQqC,kBACnCC,EAAY,IAAIC,WAAWH,GACjCrE,EAAYiC,QAAQwC,qBAAqBF,GAGzC,MAKMG,EALSC,KAAKC,KAAKL,EAAUV,OAAO,CAACgB,EAAKC,IAAQD,EAAMC,GAAO,EAAG,GAAKT,GAAgB,IAlIzE,GAwIdU,EAHYR,EAAUS,OAAQF,GAAQA,EAAM,KAAKG,OApIzB,EAyI9BxE,EAAsBiE,GAAmBK,GAErCL,EACF7D,EAAiB,gDACRkE,GACTlE,EAAiB,0CAGfX,EAAgB+B,SAClBiD,sBAAsBd,IAI1BA,KACC,IAGGe,EAAqBpD,sBAAYd,UACrC,MAAMmE,EAAcnE,UAClB,GAAKrB,EAASqC,SAAY/B,EAAgB+B,QAA1C,CAEA,IACE,MAAMD,QAAmBX,IACPzB,EAASqC,QAAS,IAAIZ,KACrCgE,oBACAC,sBACAC,sBAEH,GAAIvD,EAAWiD,OAAS,EAAG,CACzBnD,EAAiBE,GAEjB,IAAIwD,EAAiB,GACjBC,GAAe,EAEnBzD,EAAWU,QAAQ,CAACC,EAAK+C,KACvBF,UAAuBE,EAAQ,KAAOjC,EAAwBd,EAAIe,aAE9DvD,GAAuBF,EAAwBgC,QAAQgD,OAAS,IAC9ChF,EAAwBgC,QAAQe,KACjDC,GAAY5B,IAA0BsB,EAAIO,WAAYD,GAlLnD,MAoLYwC,GAAe,MAIrC9E,EAAmB6E,GACnBjF,EAAiBkF,GAEbA,EACF5E,EAAiB,8DACPL,GACVK,EAAiB,yCAGnB8E,IACAhF,EAAmB,IAErB,MAAOgB,GACPC,QAAQD,MAAM,+BAAgCA,GAG5CzB,EAAgB+B,SAClBiD,sBAAsBE,KAI1BA,KACC,CAACtD,EAAkB3B,EAAqBK,IA4BrCmF,EAAcA,KAClB,MAAMzD,EAASpC,EAAUmC,QACrBC,GACUA,EAAOE,WAAW,MAC1BK,UAAU,EAAG,EAAGP,EAAOG,MAAOH,EAAOK,SAI7C,OACEqD,IAAAC,cAAA,OAAKC,MAAO,CAAEC,UAAW,SAAUC,UAAW,OAAQC,WAAY,sBAChEL,IAAAC,cAAA,UAAI,mCACJD,IAAAC,cAAA,OAAKC,MAAO,CAAEI,SAAU,WAAYC,QAAS,iBAC3CP,IAAAC,cAAA,SAAOO,IAAKxG,EAAUyG,UAAQ,EAACC,aAAW,EAACjE,MAAM,MAAME,OAAO,QAC9DqD,IAAAC,cAAA,UAAQO,IAAKtG,EAAWgG,MAAO,CAAEI,SAAU,WAAYK,IAAK,EAAGC,KAAM,MAGvEZ,IAAAC,cAAA,OAAKC,MAAO,CAAEE,UAAW,SACrBlF,EAKA8E,IAAAC,cAAAD,IAAAa,SAAA,MACItG,GACAyF,IAAAC,cAAA,UAAQa,QA/LUzF,UAC5B,IAAKrB,EAASqC,QAAS,OAEvB,MAAMD,QAAmBX,IACPzB,EAASqC,QAAS,IAAIZ,KACrCgE,oBACAC,sBACAC,sBAECvD,EAAWiD,OAAS,GACtBhF,EAAwBgC,QAAUD,EAAW2E,IAAKhE,GAAQA,EAAIO,YAC9D9C,GAAuB,GACvBS,EAAiB,+DAEjBA,EAAiB,+CAiL+BiF,MAAO7G,GAAa,wCAI9D2G,IAAAC,cAAA,UAAQa,QArDME,KACjBzG,GAILD,EAAgB+B,SAAU,EAC1B1B,GAAiB,GACjBE,GAAsB,GACtBE,EAAmB,IACnBE,EAAiB,0CACjBsE,IACAhB,KATEtD,EAAiB,sDAmDuBiF,MAAO7G,GAAa,iCAGtD2G,IAAAC,cAAA,UAAQa,QAzCKG,KACrB3G,EAAgB+B,SAAU,EAC1B0D,IACAhF,EAAmB,IACnBJ,GAAiB,GACjBE,GAAsB,GACtBI,EAAiB,qCAmCwBiF,MAAO7G,GAAa,gCAGrD2G,IAAAC,cAAA,UAAQa,QA5NCI,KAAM,IAAAC,EACvB,MAAMC,EAAyB,QAAnBD,EAAGnH,EAASqC,eAAO,IAAA8E,OAAA,EAAhBA,EAAkBE,UAC7BD,IACFA,EAAOE,YAAYxE,QAASyE,GAAUA,EAAMC,QAC5CxH,EAASqC,QAAQgF,UAAY,MAE3BlH,EAAgBkC,UAClBlC,EAAgBkC,QAAQoF,QACxBtH,EAAgBkC,QAAU,MAE5BlB,GAAc,GACdX,GAAuB,GACvBH,EAAwBgC,QAAU,GAClCtB,EAAmB,IACnBF,GAAsB,GACtBI,EAAiB,iCA6MoBiF,MAAO7G,GAAa,6BAhBnD2G,IAAAC,cAAA,UAAQa,QAhOIzF,UAClB,IACE,MAAM+F,QAAeM,UAAUC,aAAaC,aAAa,CAAEC,OAAO,EAAMC,OAAO,IAC3E9H,EAASqC,UAASrC,EAASqC,QAAQgF,UAAYD,GAGnDjH,EAAgBkC,QAAU,IAAK0F,OAAOC,cAAgBD,OAAOE,oBAC7D,MAAMC,EAAc/H,EAAgBkC,QAAQ8F,wBAAwBf,GACpEhH,EAAYiC,QAAUlC,EAAgBkC,QAAQ+F,iBAC9CF,EAAYG,QAAQjI,EAAYiC,SAEhClB,GAAc,GACdF,EAAiB,yDACjB,MAAOc,GACPC,QAAQD,MAAM,2BAA4BA,GAC1Cd,EAAiB,4DAiNiBiF,MAAO7G,GAAa,8BAuBtD2G,IAAAC,cAAA,WACED,IAAAC,cAAA,UAAI,gCACHlC,OAAOC,QAAQlD,GAAiBiG,IAAI,CAAAuB,EAAexC,KAAK,IAAlByC,EAAMnE,GAAKkE,EAAA,OAChDtC,IAAAC,cAAA,KAAGuC,IAAK1C,GACLyC,EAAK,KAAEvC,IAAAC,cAAA,cAAS7B,OAKtB1D,GACCsF,IAAAC,cAAA,OAAKC,MAAO,CAAEvG,MAAO,MAAO8I,WAAY,OAAQrC,UAAW,SAAU,8DAKtExF,GACCoF,IAAAC,cAAA,OAAKC,MAAO,CAAEvG,MAAO,MAAO8I,WAAY,OAAQrC,UAAW,SAAU,mEAKvEJ,IAAAC,cAAA,OAAKC,MAAO,CAAEE,UAAW,OAAQqC,WAAY,OAAQ9I,MAAOe,GAAiBE,EAAqB,MAAQ,UACvGI,KChTM0H,MAZSC,IAClBA,GAAeA,aAAuBC,UACxCC,EAAAC,EAAA,GAAAC,KAAAF,EAAAG,KAAA,UAAqBD,KAAK5E,IAAiD,IAAhD8E,OAAEA,EAAMC,OAAEA,EAAMC,OAAEA,EAAMC,OAAEA,EAAMC,QAAEA,GAASlF,EACpE8E,EAAON,GACPO,EAAOP,GACPQ,EAAOR,GACPS,EAAOT,GACPU,EAAQV,MCDDW,IAASC,WAAWC,SAASC,eAAe,SACpDC,OACH1D,IAAAC,cAACD,IAAM2D,WAAU,KACf3D,IAAAC,cAAClG,EAAG,QAGR2I","file":"static/js/main.aa760454.chunk.js","sourcesContent":["import React, { useEffect, useRef, useState, useCallback } from \"react\";\nimport * as faceapi from \"face-api.js\";\n\nconst App = () => {\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const audioContextRef = useRef(null);\n  const analyserRef = useRef(null);\n\n  const referenceDescriptorsRef = useRef([]);\n  const isMonitoringRef = useRef(false);\n\n  const [isReferenceCaptured, setIsReferenceCaptured] = useState(false);\n  const [proxyDetected, setProxyDetected] = useState(false);\n  const [audioProxyDetected, setAudioProxyDetected] = useState(false);\n  const [faceExpressions, setFaceExpressions] = useState({});\n  const [statusMessage, setStatusMessage] = useState(\"Loading models...\");\n  const [isCameraOn, setIsCameraOn] = useState(false);\n\n  const TOLERANCE = 0.5;\n  const NOISE_THRESHOLD = 0.4; // Adjust based on environment\n  const MULTIPLE_VOICES_THRESHOLD = 5; // Number of frequency peaks indicating multiple voices\n\n  // ✅ Load Models\n  useEffect(() => {\n    const loadModels = async () => {\n      try {\n        const modelPath = `${process.env.PUBLIC_URL}/models`; // Ensures correct path in production\n    \n        await Promise.all([\n          faceapi.nets.tinyFaceDetector.loadFromUri(modelPath),\n          faceapi.nets.faceLandmark68Net.loadFromUri(modelPath),\n          faceapi.nets.faceRecognitionNet.loadFromUri(modelPath),\n          faceapi.nets.faceExpressionNet.loadFromUri(modelPath),\n        ]);\n    \n        setStatusMessage(\"✅ Models loaded. Click 'Start Camera'.\");\n      } catch (error) {\n        console.error(\"Error loading models:\", error);\n        setStatusMessage(\"❗ Error loading models. Please reload the page.\");\n      }\n    };\n    \n    loadModels();\n  }, []);\n\n  // 🎥 Start Camera & Microphone\n  const startCamera = async () => {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });\n      if (videoRef.current) videoRef.current.srcObject = stream;\n\n      // Initialize audio context\n      audioContextRef.current = new (window.AudioContext || window.webkitAudioContext)();\n      const audioStream = audioContextRef.current.createMediaStreamSource(stream);\n      analyserRef.current = audioContextRef.current.createAnalyser();\n      audioStream.connect(analyserRef.current);\n\n      setIsCameraOn(true);\n      setStatusMessage(\"📸 Camera started. Capture reference photo.\");\n    } catch (error) {\n      console.error(\"Error accessing devices:\", error);\n      setStatusMessage(\"❗ Please allow camera and microphone permissions.\");\n    }\n  };\n\n  // ⏹️ Stop Camera & Microphone\n  const stopCamera = () => {\n    const stream = videoRef.current?.srcObject;\n    if (stream) {\n      stream.getTracks().forEach((track) => track.stop());\n      videoRef.current.srcObject = null;\n    }\n    if (audioContextRef.current) {\n      audioContextRef.current.close();\n      audioContextRef.current = null;\n    }\n    setIsCameraOn(false);\n    setIsReferenceCaptured(false);\n    referenceDescriptorsRef.current = [];\n    setFaceExpressions({});\n    setAudioProxyDetected(false);\n    setStatusMessage(\"⏹️ Camera stopped.\");\n  };\n\n  // 📸 Capture Reference Photo\n  const captureReferencePhoto = async () => {\n    if (!videoRef.current) return;\n\n    const detections = await faceapi\n      .detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions())\n      .withFaceLandmarks()\n      .withFaceDescriptors()\n      .withFaceExpressions();\n\n    if (detections.length > 0) {\n      referenceDescriptorsRef.current = detections.map((det) => det.descriptor);\n      setIsReferenceCaptured(true);\n      setStatusMessage(\"✅ Reference photo captured! Click 'Start Monitoring'.\");\n    } else {\n      setStatusMessage(\"❗ No face detected! Please try again.\");\n    }\n  };\n\n  // ✨ Draw Face Boxes and Expressions\n  const drawFaceTracking = useCallback((detections) => {\n    if (!canvasRef.current || !videoRef.current) return;\n\n    const canvas = canvasRef.current;\n    const ctx = canvas.getContext(\"2d\");\n    canvas.width = videoRef.current.videoWidth;\n    canvas.height = videoRef.current.videoHeight;\n    ctx.clearRect(0, 0, canvas.width, canvas.height);\n\n    detections.forEach((det) => {\n      const { x, y, width, height } = det.detection.box;\n      const color =\n        referenceDescriptorsRef.current.some(\n          (refDesc) => faceapi.euclideanDistance(det.descriptor, refDesc) < TOLERANCE\n        )\n          ? \"green\"\n          : \"red\";\n\n      ctx.strokeStyle = color;\n      ctx.lineWidth = 3;\n      ctx.strokeRect(x, y, width, height);\n\n      ctx.font = \"16px Arial\";\n      ctx.fillStyle = color;\n      ctx.fillText(getMostLikelyExpression(det.expressions), x, y - 5);\n    });\n  }, []);\n\n  // 💡 Get Most Likely Expression\n  const getMostLikelyExpression = (expressions) => {\n    return Object.entries(expressions).reduce((acc, [expr, value]) =>\n      value > acc.value ? { expression: expr, value } : acc\n    , { expression: \"\", value: 0 }).expression;\n  };\n\n  // 🎙️ Audio Detection Loop\n  const startAudioDetection = useCallback(() => {\n    const detectAudio = () => {\n      if (!isMonitoringRef.current || !analyserRef.current) return;\n\n      const bufferLength = analyserRef.current.frequencyBinCount;\n      const dataArray = new Uint8Array(bufferLength);\n      analyserRef.current.getByteFrequencyData(dataArray);\n\n      // Calculate volume (RMS - Root Mean Square)\n      const volume = Math.sqrt(dataArray.reduce((sum, val) => sum + val ** 2, 0) / bufferLength) / 255;\n\n      // Detect multiple voices based on frequency peaks\n      const peakCount = dataArray.filter((val) => val > 150).length; // Adjust threshold for multiple voices\n\n      const isNoiseDetected = volume > NOISE_THRESHOLD;\n      const isMultipleVoices = peakCount > MULTIPLE_VOICES_THRESHOLD;\n\n      setAudioProxyDetected(isNoiseDetected || isMultipleVoices);\n\n      if (isNoiseDetected) {\n        setStatusMessage(\"🚨 Proxy in Audio! Noise detected!\");\n      } else if (isMultipleVoices) {\n        setStatusMessage(\"🚨 Multiple Voices Detected!\");\n      }\n\n      if (isMonitoringRef.current) {\n        requestAnimationFrame(detectAudio);\n      }\n    };\n\n    detectAudio();\n  }, []);\n\n  // 🔄 Face Detection Loop\n  const startFaceDetection = useCallback(async () => {\n    const detectFaces = async () => {\n      if (!videoRef.current || !isMonitoringRef.current) return;\n\n      try {\n        const detections = await faceapi\n          .detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions())\n          .withFaceLandmarks()\n          .withFaceDescriptors()\n          .withFaceExpressions();\n\n        if (detections.length > 0) {\n          drawFaceTracking(detections);\n\n          let newExpressions = {};\n          let isProxyFound = false;\n\n          detections.forEach((det, index) => {\n            newExpressions[`Face ${index + 1}`] = getMostLikelyExpression(det.expressions);\n\n            if (isReferenceCaptured && referenceDescriptorsRef.current.length > 0) {\n              const isKnownFace = referenceDescriptorsRef.current.some(\n                (refDesc) => faceapi.euclideanDistance(det.descriptor, refDesc) < TOLERANCE\n              );\n              if (!isKnownFace) isProxyFound = true;\n            }\n          });\n\n          setFaceExpressions(newExpressions);\n          setProxyDetected(isProxyFound);\n\n          if (isProxyFound) {\n            setStatusMessage(\"🚨 Proxy detected! Unauthorized person detected!\");\n          } else if (!audioProxyDetected) {\n            setStatusMessage(\"✅ Monitoring in progress...\");\n          }\n        } else {\n          clearCanvas();\n          setFaceExpressions({});\n        }\n      } catch (error) {\n        console.error(\"Error during face detection:\", error);\n      }\n\n      if (isMonitoringRef.current) {\n        requestAnimationFrame(detectFaces);\n      }\n    };\n\n    detectFaces();\n  }, [drawFaceTracking, isReferenceCaptured, audioProxyDetected]);\n\n  // ▶️ Start Monitoring\n  const startMonitoring = () => {\n    if (!isReferenceCaptured) {\n      setStatusMessage(\"❗ Please capture your reference photo first.\");\n      return;\n    }\n    isMonitoringRef.current = true;\n    setProxyDetected(false);\n    setAudioProxyDetected(false);\n    setFaceExpressions({});\n    setStatusMessage(\"🔎 Monitoring in progress...\");\n    startFaceDetection();\n    startAudioDetection();\n  };\n\n  // ⏹️ Stop Monitoring\n  const stopMonitoring = () => {\n    isMonitoringRef.current = false;\n    clearCanvas();\n    setFaceExpressions({});\n    setProxyDetected(false);\n    setAudioProxyDetected(false);\n    setStatusMessage(\"⏹️ Monitoring stopped.\");\n  };\n\n  // 🧹 Clear Canvas\n  const clearCanvas = () => {\n    const canvas = canvasRef.current;\n    if (canvas) {\n      const ctx = canvas.getContext(\"2d\");\n      ctx.clearRect(0, 0, canvas.width, canvas.height);\n    }\n  };\n\n  return (\n    <div style={{ textAlign: \"center\", marginTop: \"20px\", fontFamily: \"Arial, sans-serif\" }}>\n      <h1>Advanced Proxy Detection System</h1>\n      <div style={{ position: \"relative\", display: \"inline-block\" }}>\n        <video ref={videoRef} autoPlay playsInline width=\"640\" height=\"480\"></video>\n        <canvas ref={canvasRef} style={{ position: \"absolute\", top: 0, left: 0 }} />\n      </div>\n\n      <div style={{ marginTop: \"10px\" }}>\n        {!isCameraOn ? (\n          <button onClick={startCamera} style={buttonStyle}>\n            📸 Start Camera\n          </button>\n        ) : (\n          <>\n            {!isReferenceCaptured && (\n              <button onClick={captureReferencePhoto} style={buttonStyle}>\n                📷 Capture Reference Photo\n              </button>\n            )}\n            <button onClick={startMonitoring} style={buttonStyle}>\n              ▶️ Start Monitoring\n            </button>\n            <button onClick={stopMonitoring} style={buttonStyle}>\n              ⏹️ Stop Monitoring\n            </button>\n            <button onClick={stopCamera} style={buttonStyle}>\n              🚫 Stop Camera\n            </button>\n          </>\n        )}\n      </div>\n\n      <div>\n        <h3>Detected Facial Expressions:</h3>\n        {Object.entries(faceExpressions).map(([face, expr], index) => (\n          <p key={index}>\n            {face}: <strong>{expr}</strong>\n          </p>\n        ))}\n      </div>\n\n      {proxyDetected && (\n        <div style={{ color: \"red\", fontWeight: \"bold\", marginTop: \"10px\" }}>\n          🚨 Proxy Detected! Unauthorized person detected!\n        </div>\n      )}\n\n      {audioProxyDetected && (\n        <div style={{ color: \"red\", fontWeight: \"bold\", marginTop: \"10px\" }}>\n          🚨 Proxy in Audio! Noise or Multiple Voices Detected!\n        </div>\n      )}\n\n      <div style={{ marginTop: \"20px\", fontWeight: \"bold\", color: proxyDetected || audioProxyDetected ? \"red\" : \"green\" }}>\n        {statusMessage}\n      </div>\n    </div>\n  );\n};\n\n// 🌟 Button Styles\nconst buttonStyle = {\n  margin: \"5px\",\n  padding: \"10px 15px\",\n  border: \"none\",\n  borderRadius: \"8px\",\n  backgroundColor: \"#4CAF50\",\n  color: \"#fff\",\n  fontSize: \"16px\",\n  cursor: \"pointer\",\n  transition: \"background-color 0.3s\",\n};\nexport default App;\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nconst root = ReactDOM.createRoot(document.getElementById('root'));\nroot.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>\n);\nreportWebVitals();\n"],"sourceRoot":""}